---
layout: post
title: Songs That (Still) Rock
subtitle: Analysis of Popular Music From 1960 to 2000
cover-img: /assets/img/image3.jpg
thumbnail-img: /assets/img/image3.jpg
tags: [Python, ML]
---

I've always been a huge fan of music but something about today's music doesn't hit the right notes in my brain like the older ones do. Something about the Stones and Bob Dylan makes me move, gets me excited; Drake and Taylor Swift not so much. But why is that exactly? Is it just a preference I was taught, or is there any analyzable data out there that can give better insight? Luckily, Kaggle had the exact dataset that helped me try to answer that question exactly!
 
## Dataset
The dataset consists of over 170,000 observations, and multiple different features including popularity, danceability, loudness, and many more. A deep dive at the data showed one of its most obvious faults: popularity was extremely unbalanced. According to Spotify the popularity is based on the "total number of plays the track has had and how recent those plays are.
Generally speaking, songs that are being played a lot now will have a higher popularity than songs that were played a lot in the past." This caused a huge recency bias in the feature, so I decided to focus my project on songs from 1960 to 2000. Furthermore I did some basic data cleaning and engineering which can be explored more in my notebook.
 
## Problem
With a wrangled dataset ready to be put through a model, I decided what question I was going to explore: Can a model accurately predict which era a song was released in? To start, I created a target called era and broke my dataset into 4 distinct ones: 60s, 70s, 80s, and 90s. Also because I wanted to get an idea of what made a song belong to each era, I decided to subset the data into the top 2000 songs of each era. With this new data frame consisting of the top 2000 songs of each era, I was ready to train my model.
 
## Model
Split the data into my target vector (era) and my feature matrix. After that I did a train, val, test split, followed by establishing the baseline as 25%. I fitted 3 different models: Logistic Regression, Random Forest Classifier, and XGB Classifier. The accuracy was highest for the XGB Model so I decided to use it for further analysis.
 
![](/assets/img/image1.PNG)

The model had high precision when predicting songs that belonged to the 60s and 90s. The 70s and 80s weren't as precise, but did beat the 25% baseline by a lot.
 
## Results
![](/assets/img/image2.png)

As you can see from our permutation importances, the 4 features that influenced the model's accuracy the most were popularity, duration, loudness, and energy. Below you will see each of these features distribution for comparison between eras.


![](/assets/img/image4.png) | ![](/assets/img/image5.png)
![](/assets/img/image6.png) | ![](/assets/img/image7.png)

Finally, we use our model on our test set to see how accurate we were.

![](/assets/img/image8.PNG)



